{
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "name": "",
  "signature": "sha256:461ccc80bcc62820c4d47abfad27b0d13b0cbbd448c4989222bea05e1abe62c7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Linear state-space model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This example is also available as [an IPython notebook](lssm.ipynb) or [a Python script](lssm.py).\n",
      "\n",
      "In linear state-space models a sequence of $M$-dimensional observations $\\mathbf{Y}=(\\mathbf{y}_1,\\ldots,\\mathbf{y}_N)$ is assumed to be generated from latent $D$-dimensional states $\\mathbf{X}=(\\mathbf{x}_1,\\ldots,\\mathbf{x}_N)$ which follow a first-order Markov process:\n",
      "\n",
      "$$\n",
      "\\mathbf{x}_{n} &= \\mathbf{A}\\mathbf{x}_{n-1} + \\text{noise} \\,,\n",
      "\\\\\n",
      "\\mathbf{y}_{n} &= \\mathbf{C}\\mathbf{x}_{n} + \\text{noise} \\,,\n",
      "$$\n",
      "\n",
      "where the noise is Gaussian, $\\mathbf{A}$ is the $D\\times D$ state dynamics matrix and $\\mathbf{C}$ is the $M\\times D$ loading matrix. Usually, the latent space dimensionality $D$ is assumed to be much smaller than the observation space dimensionality $M$ in order to model the dependencies of high-dimensional observations efficiently.\n",
      "\n",
      "First, let us generate some toy data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "M = 30\n",
      "N = 400\n",
      "\n",
      "w = 0.3\n",
      "a = np.array([[np.cos(w), -np.sin(w), 0, 0], \n",
      "              [np.sin(w), np.cos(w),  0, 0], \n",
      "              [0,         0,          1, 0],\n",
      "              [0,         0,          0, 0]])\n",
      "c = np.random.randn(M,4)\n",
      "x = np.empty((N,4))\n",
      "f = np.empty((M,N))\n",
      "y = np.empty((M,N))\n",
      "x[0] = 10*np.random.randn(4)\n",
      "f[:,0] = np.dot(c,x[0])\n",
      "y[:,0] = f[:,0] + 3*np.random.randn(M)\n",
      "for n in range(N-1):\n",
      "    x[n+1] = np.dot(a,x[n]) + np.random.randn(4)\n",
      "    f[:,n+1] = np.dot(c,x[n+1])\n",
      "    y[:,n+1] = f[:,n+1] + 3*np.random.randn(M)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "The linear state-space model can be constructed as follows:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bayespy.inference.vmp.nodes.gaussian_markov_chain import GaussianMarkovChain\n",
      "from bayespy.inference.vmp.nodes.gaussian import GaussianARD\n",
      "from bayespy.inference.vmp.nodes.gamma import Gamma\n",
      "from bayespy.inference.vmp.nodes.dot import SumMultiply\n",
      "\n",
      "D = 10\n",
      "\n",
      "# Dynamics matrix with ARD\n",
      "alpha = Gamma(1e-5,\n",
      "              1e-5,\n",
      "              plates=(D,),\n",
      "              name='alpha')\n",
      "A = GaussianARD(0,\n",
      "                alpha,\n",
      "                shape=(D,),\n",
      "                plates=(D,),\n",
      "                name='A')\n",
      "\n",
      "# Latent states with dynamics\n",
      "X = GaussianMarkovChain(np.zeros(D),         # mean of x0\n",
      "                        1e-3*np.identity(D), # prec of x0\n",
      "                        A,                   # dynamics\n",
      "                        np.ones(D),          # innovation\n",
      "                        n=N,                 # time instances\n",
      "                        name='X',\n",
      "                        initialize=False)\n",
      "X.initialize_from_value(np.zeros((N,D))) # just some empty values, X is\n",
      "                                         # updated first anyway\n",
      "\n",
      "# Mixing matrix from latent space to observation space using ARD\n",
      "gamma = Gamma(1e-5,\n",
      "              1e-5,\n",
      "              plates=(D,),\n",
      "              name='gamma')\n",
      "C = GaussianARD(0,\n",
      "                gamma,\n",
      "                shape=(D,),\n",
      "                plates=(M,1),\n",
      "                name='C')\n",
      "# Initialize nodes (must use some randomness for C, and update X before C)\n",
      "C.initialize_from_random()\n",
      "\n",
      "# Observation noise\n",
      "tau = Gamma(1e-5,\n",
      "            1e-5,\n",
      "            name='tau')\n",
      "\n",
      "# Observations\n",
      "F = SumMultiply('i,i',\n",
      "                C, \n",
      "                X,\n",
      "                name='F')\n",
      "Y = GaussianARD(F,\n",
      "                tau,\n",
      "                name='Y')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "An inference machine using variational Bayesian inference with variational\n",
      "message passing is then construced as\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bayespy.inference.vmp.vmp import VB\n",
      "Q = VB(X, C, gamma, A, alpha, tau, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Observe the data partially (80% is marked missing):\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bayespy.utils import random\n",
      "\n",
      "# Add missing values randomly (keep only 20%)\n",
      "mask = random.mask(M, N, p=0.2)\n",
      "Y.observe(y, mask=mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then inference (100 iterations) can be run simply as"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q.update(repeat=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration 1: loglike=-3.118644e+04 (0.210 seconds)\n",
        "Iteration 2: loglike=-1.129540e+04 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 3: loglike=-9.139376e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 4: loglike=-8.704676e+03 (0.220 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 5: loglike=-8.531889e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 6: loglike=-8.386198e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 7: loglike=-8.255826e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 8: loglike=-8.176274e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 9: loglike=-8.139579e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 10: loglike=-8.117779e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Speeding up with parameter expansion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "VB inference can converge extremely slowly if the variables are strongly coupled.  Because VMP updates one variable at a time, it may lead to slow zigzagging.  This can be solved by using parameter expansion which reduces the coupling. In state-space models, the states $\\mathbf{x}_n$ and the loadings $\\mathbf{C}$ are coupled through a dot product $\\mathbf{Cx}_n$, which is unaltered if the latent space is rotated arbitrarily:\n",
      "\n",
      "$$\n",
      "\\mathbf{y}_n &= \\mathbf{C}\\mathbf{x}_n = \\mathbf{C}\\mathbf{R}^{-1}\\mathbf{R}\\mathbf{x}_n \\,.\n",
      "$$\n",
      "\n",
      "Thus, one intuitive transformation would be $\\mathbf{C}\\rightarrow\\mathbf{C}\\mathbf{R}^{-1}$ and $\\mathbf{X}\\rightarrow\\mathbf{R}\\mathbf{X}$.  In order to keep the dynamics of the latent states unaffected by the transformation, the state dynamics matrix $\\mathbf{A}$ must be transformed accordingly:\n",
      "\n",
      "$$\n",
      "\\mathbf{R}\\mathbf{x}_n &= \\mathbf{R}\\mathbf{A}\\mathbf{R}^{-1} \\mathbf{R}\\mathbf{x}_{n-1} \\,,\n",
      "$$\n",
      "\n",
      "resulting in a transformation $\\mathbf{A}\\rightarrow\\mathbf{R}\\mathbf{A}\\mathbf{R}^{-1}$.  For more details, refer to *Fast Variational Bayesian Linear State-Space Model (Luttinen, 2013).\n",
      "\n",
      "In BayesPy, the transformations can be used as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the parameter expansion module\n",
      "from bayespy.inference.vmp import transformations\n",
      "\n",
      "# Rotator of the state dynamics matrix\n",
      "rotA = transformations.RotateGaussianARD(Q['A'], Q['alpha'])\n",
      "# Rotator of the states (includes rotation of the state dynamics matrix)\n",
      "rotX = transformations.RotateGaussianMarkovChain(Q['X'], rotA)\n",
      "# Rotator of the loading matrix\n",
      "rotC = transformations.RotateGaussianARD(Q['C'], Q['gamma'])\n",
      "# Rotation optimizer\n",
      "R = transformations.RotationOptimizer(rotX, rotC, D)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that it is crucial to select the correct rotation class which corresponds\n",
      "to the particular model block exactly.  The rotation can be performed after each\n",
      "full VB update:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ind in range(10):\n",
      "    Q.update()\n",
      "    R.rotate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration 11: loglike=-8.100983e+03 (0.210 seconds)\n",
        "Iteration 12: loglike=-7.622913e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 13: loglike=-7.452057e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 14: loglike=-7.385975e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 15: loglike=-7.351449e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 16: loglike=-7.331026e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 17: loglike=-7.317997e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 18: loglike=-7.309212e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 19: loglike=-7.303074e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 20: loglike=-7.298661e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to implement your own rotations or check the existing ones, you may\n",
      "use debugging utilities:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ind in range(10):\n",
      "    Q.update()\n",
      "    R.rotate(check_bound=True,\n",
      "             check_gradient=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration 21: loglike=-7.295401e+03 (0.210 seconds)\n",
        "Norm of numerical gradient: 3905.05"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  3905.05\n",
        "Gradient relative error = 6.39002e-05 and absolute error = 0.249533\n",
        "Iteration 22: loglike=-7.292861e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 6245.37"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 6.39002e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n",
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 7.56396e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  6245.43\n",
        "Gradient relative error = 7.56396e-05 and absolute error = 0.472397\n",
        "Iteration 23: loglike=-7.290841e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 3984.43"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  3984.43\n",
        "Gradient relative error = 6.78117e-05 and absolute error = 0.270191\n",
        "Iteration 24: loglike=-7.289243e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 13053.7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 6.78117e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n",
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 2.65118e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  13053.8\n",
        "Gradient relative error = 2.65118e-05 and absolute error = 0.346078\n",
        "Iteration 25: loglike=-7.287794e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 4144.61"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  4144.59\n",
        "Gradient relative error = 7.02612e-05 and absolute error = 0.291205\n",
        "Iteration 26: loglike=-7.286531e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 5821.72"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 7.02612e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n",
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 4.57892e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  5821.73\n",
        "Gradient relative error = 4.57892e-05 and absolute error = 0.266572\n",
        "Iteration 27: loglike=-7.285469e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 15766.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  15766.4\n",
        "Gradient relative error = 3.5184e-05 and absolute error = 0.554724\n",
        "Iteration 28: loglike=-7.284584e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 5782.51"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 3.5184e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n",
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 5.61705e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  5782.51\n",
        "Gradient relative error = 5.61705e-05 and absolute error = 0.324807\n",
        "Iteration 29: loglike=-7.283818e+03 (0.210 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 9067.22"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  9067.21\n",
        "Gradient relative error = 2.4973e-05 and absolute error = 0.226435\n",
        "Iteration 30: loglike=-7.283121e+03 (0.200 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of numerical gradient: 9594.54"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 2.4973e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n",
        "/home/jluttine/workspace/bayespy/bayespy/inference/vmp/transformations.py:142: UserWarning: Rotation gradient has relative error 5.43175e-05\n",
        "  warnings.warn(\"Rotation gradient has relative error %g\" % err)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of function gradient:  9594.62\n",
        "Gradient relative error = 5.43175e-05 and absolute error = 0.521151\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}