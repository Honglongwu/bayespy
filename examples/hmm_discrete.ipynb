{
 "metadata": {
  "name": "",
  "signature": "sha256:d537be90c89280ae920988bb629fa0943ad7058eee9c598a31861f4fc6e512c5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Discrete hidden Markov model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This example is also available as [an IPython notebook](hmm_discrete.ipynb) or [a Python script](hmm_discrete.py)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Known parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This example follows the one presented in [Wikipedia](http://en.wikipedia.org/wiki/Hidden_Markov_model#A_concrete_example). Each day, the state of the weather is either 'rainy' or 'sunny'. The weather follows a first-order discrete Markov process with the following initial state probability and state transition probabilities:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bayespy.nodes import CategoricalMarkovChain\n",
      "# Initial state probabilities\n",
      "a0 = [0.6, 0.4] # p(rainy)=0.6, p(sunny)=0.4\n",
      "# State transition probabilities\n",
      "A = [[0.7, 0.3], # p(rainy->rainy)=0.7, p(rainy->sunny)=0.3\n",
      "     [0.4, 0.6]] # p(sunny->rainy)=0.4, p(sunny->sunny)=0.6\n",
      "# The length of the process\n",
      "N = 1000\n",
      "# Markov chain\n",
      "Z = CategoricalMarkovChain(a0, A, states=N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, instead of observing this process directly, we observe whether Bob is 'walking', 'shopping' or 'cleaning'. The probability of each activity depends on the current weather as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bayespy.nodes import Categorical, Mixture\n",
      "# Emission probabilities\n",
      "P = [[0.1, 0.4, 0.5],\n",
      "     [0.6, 0.3, 0.1]]\n",
      "# Observed process\n",
      "Y = Mixture(Z, Categorical, P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to test our method, we'll generate artificial data using this model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Draw realization of the weather process\n",
      "weather = Z.random()\n",
      "# Using this weather, draw realizations of the activities\n",
      "activity = Mixture(weather, Categorical, P).random()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, using this data, we set our variable $Y$ to be observed:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y.observe(activity)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to run inference, we construct variational Bayesian inference engine:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bayespy.inference import VB\n",
      "Q = VB(Y, Z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that we need to give all random variables to `VB`. In this case, the only random variables were `Y` and `Z`. Next we run the inference, that is, compute our posterior distribution:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q.update()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration 1: loglike=-1.091583e+03 (0.090 seconds)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, because there is only one unobserved random variable, we recover the exact posterior distribution and there is no need to iterate more than one step."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Unknown parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we consider the case when we do not know the parameters of the weather process (initial state probability and state transition probabilities). We give these parameters quite non-informative priors, but it is possible to provide more informative priors if such information is available. First, the weather process:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bayespy.nodes import Dirichlet\n",
      "# Initial state probabilities\n",
      "a0 = Dirichlet([0.1, 0.1])\n",
      "# State transition probabilities\n",
      "A = Dirichlet([[0.1, 0.1],\n",
      "               [0.1, 0.1]])\n",
      "# Markov chain\n",
      "Z = CategoricalMarkovChain(a0, A, states=N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Second, the emission probabilities are also given quite non-informative priors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Emission probabilities\n",
      "P = Dirichlet([[0.1, 0.1, 0.1],\n",
      "               [0.1, 0.1, 0.1]])\n",
      "# Observed process\n",
      "Y = Mixture(Z, Categorical, P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " We use the same data as before:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y.observe(activity)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because `VB` takes all the unknown variables, we need to provide `A`, `a0` and `P` also:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q = VB(Y, Z, A, a0, P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we ran the VB algorithm now, we would get a result where all both states would have identical emission probability distribution. This happens because of a non-random default initialization. `P` is initialized in such a way that both states have the same distribution, and `Z` is initialized in such a way that each state has equal probability. Thus, the VB algorithm won't separate them. In such cases, it is necessary to use a random initialization. In principle, it is possible to use random initialization for either variable and then update the other variable first. In the case of mixture distributions, it might be better to initialize the parameters (`P`) randomly and update the state assignments (`Z`) first."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P.initialize_from_random()\n",
      "Q.update(Z, A, a0, P, repeat=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration 1: loglike=-1.115941e+03 (0.090 seconds)\n",
        "Iteration 2: loglike=-1.115671e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 3: loglike=-1.115603e+03 (0.100 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 4: loglike=-1.115574e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 5: loglike=-1.115555e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 6: loglike=-1.115538e+03 (0.100 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 7: loglike=-1.115521e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 8: loglike=-1.115504e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 9: loglike=-1.115487e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 10: loglike=-1.115469e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 11: loglike=-1.115451e+03 (0.100 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 12: loglike=-1.115433e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 13: loglike=-1.115413e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 14: loglike=-1.115394e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 15: loglike=-1.115374e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 16: loglike=-1.115354e+03 (0.100 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 17: loglike=-1.115333e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 18: loglike=-1.115312e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 19: loglike=-1.115290e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 20: loglike=-1.115268e+03 (0.090 seconds)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to update the variables in that order, one may explicitly give the nodes in that order to the `update` method. However, the default update order is the one used when constructing `Q`, which is the same in this case, thus we could have ignored listing the nodes to the `update` method."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the estimated state transition probabilities:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# NOTE: These three lines are just to enable inline plotting in IPython Notebooks.\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "plt.plot([])\n",
      "# Plot the state transition matrix\n",
      "import bayespy.plot.plotting as bpplt\n",
      "bpplt.dirichlet_hinton(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABG5JREFUeJzt3DFu20AARUEqEMBSOi5LlTyuXbJiihRJADeCaCz1PHMB\nfyyMp9UWuuz7vk8AZPwaPQCAYwk7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPEXEcP\nqLjf79Pn5+foGfDj3G636ePjY/SMU7n4EbBjXC6X6fF4jJ4BP87j8Zhk7H+eYgBihB0gRtgBYoQd\nIEbYAWKEHSBG2AFihB0gRtgBYoQdIEbYAWKEHSDGrzvCC5ZlmeZ5Hj3j7W3bNq3rOnpGhhs7vEDU\nj+EcjyXsADGeYk7E1/rn+PoOX3NjPxFRf47zgq8JO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPE\nCDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QI\nO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7\nQIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtA\njLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CM\nsAPECPuJbNs2esJbcV7wtevoAfy1ruvoCUCAGztAjLDDCzwHHcM5HstTDLzA8xln5MYOECPsADHC\nDhAj7AAxwg4QI+wAMcIOECPsADHCDhAj7AAxwg4QI+wAMcIOECPsADHCDhAj7AAxwg4QI+wAMcIO\nECPsADHCDhAj7AAxwg4QI+wAMcIOECPsADHCDhAj7AAxwg4Qcx09gGlalmWa53n0jLe2bdu0ruvo\nGXAKwn4Cov660Wfow/l5Poy/j6cYOICoP8+ZfR9hB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAY\nYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhh\nB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEH\niBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeI\nEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gR\ndoAYYQeIEXaAGGGHA2zbNnrC23Fm3+c6egB//sHneR49462NjsS6rkP/PvxL2E9AFIAjeYoBiBF2\ngBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gJjLvu/76BEAHMeNHSBG\n2AFihB0gRtgBYoQdIEbYAWKEHSBG2AFihB0gRtgBYoQdIEbYAWKEHSBG2AFihB0gRtgBYoQdIEbY\nAWKEHSBG2AFifgMaz1B59mVq0gAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f0aea80ef90>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the estimated emission probabilities:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bpplt.dirichlet_hinton(P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABINJREFUeJzt3TFq40AYgFHtYnCbG/laLlPqWjmSS1XeJixsAgsximby\n+b0L6NcUH4PReH7d7/f7AkDG79EDALAvYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2\ngJjTUQ96eXlZbrfbUY8DSHjk77wOC/vtdlteX1+PehzA0/JTDECMsAPECDtAjLADxAg7QIywA8QI\nO0CMsAPECDtAzGEnT7/qer0u5/N59BhJ27Yt67qOHgP4JtPu2EX9+1hbaJs27AA8RtgBYoQdIEbY\nAWKEHSBG2AFihB0gRtgBYqY9eQrMy8nwz2Y60W3HDnyZqH8205oIO0CMsAPECDtAjLADxAg7QIyw\nA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLAD\nxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPE\nCDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QI\nO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsANftm3b6BGmM9Oa\nnEYPAPw867qOHoH/sGMHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiJk27DN97F9jbaFt2gNKDkAAPGba\nHTsAjxF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAY\nYQeIEXaAGGEHiJn2zlN+luv1upzP59FjPKVt29wRzD/s2NmFqI9j7flI2AFihB0gRtgBYoQdIEbY\nAWKEHSBG2AFihB0gRtgBYoQdIEbYAWKEHSBG2AFihB0gRtgBYoQdIMYNSsAunukWrdlvrbJjB3bx\nLFFflvnfVdgBYoQdIEbYAWKEHSBG2AFihB0gRtgBYoQdIEbYAWKEHSBG2AFihB0gRtgBYoQdIEbY\nAWKEHSBG2AFihB0gRtgBYoQdIEbYAWKEHSBG2AFihB0gRtgBYoQdIEbYAWKEfQeXy2W5XC6jxwBY\nlmVZTqMHKHh7exs9AsBfduwAMcIOECPsADHCDhAj7AAxwg4QI+wAMcIOECPsADHCDhAj7AAxwg4Q\nI+wAMcIOECPsADHCDhAj7AAxwg4QI+wAMcIOECPsADHCDhAj7AAxwg4QI+wAMcIOECPsADHCDuxi\n27bRIxxm9nc9jR4AaFjXdfQIvLNjB4gRdoAYYQeIEXaAGGEHiBF2gBhhB4gRdoAYYQeIEXaAGGEH\niBF2gBhhB4gRdoAYYQeIEXaAGGFnF7PfKFNm7fnIDUrswu05MA87doAYYQeIEXaAGGEHiBF2gBhh\nB4gRdoCYw75jv9/vRz0K4KnZsQPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAjLADxAg7QIywA8QI\nO0CMsAPECDtAjLADxAg7QIywA8QIO0CMsAPECDtAzB9sJU2B0vzILgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f0aea80ee90>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is interesting that these estimated parameters are very different from the true parameters. This happens because of un-identifiability: different parameters lead to similar marginal distributions over the observed process."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}